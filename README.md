# Customer Complaint Severity Classification

## ğŸ¯ Objective
Train a deep learning model to classify **customer complaint severity** into `low`, `medium`, or `high`.  
The model is then exposed through a **FastAPI** endpoint for integration with a dashboard or any frontend system.

---

## ğŸ§  Project Overview

### Pipeline
1. **Data Preprocessing** â€” Clean complaint narratives, remove noise, and normalize text.  
2. **Weak Supervision** â€” Generate pseudo-labels (`low`, `medium`, `high`) using TextBlob polarity and escalation keywords.  
3. **Deep Learning Model** â€” Train a Bidirectional LSTM classifier using TensorFlow/Keras.  
4. **Evaluation & Visualization** â€” Plot accuracy/loss, confusion matrix, class distribution, and word clouds.  
5. **Deployment** â€” Convert trained model into a **FastAPI** inference service.  
6. **Dashboard Integration** â€” Frontend consumes the API endpoint to visualize and prioritize complaints.

---

## ğŸ§© Repository Structure

```
customer-severity-classifier/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ complaints_raw.csv
â”‚   â””â”€â”€ complaints_processed.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ severity_classifier_tf_viz.ipynb
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ severity_lstm_tf.keras
â”‚   â”œâ”€â”€ severity_lstm_tf_tokenizer.pkl
â”‚   â””â”€â”€ severity_lstm_tf_labels.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ model_train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ infer.py
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸš€ Setup Instructions

### 1. Create environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

### 2. Train model
Open `notebooks/severity_classifier_tf_viz.ipynb` and run all cells.  
Artifacts (model, tokenizer, labels) will be saved in `artifacts/`.

### 3. Run API
```bash
uvicorn api.main:app --reload
```
Access the API docs at: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

### 4. Example API request
**POST** `/predict`
```json
{
  "text": "My account was closed without prior notice."
}
```

**Response**
```json
{
  "severity": "high",
  "confidence": 0.92
}
```

---

## ğŸ§® Model Details
- Architecture: **Bidirectional LSTM**
- Embedding Dim: `128`
- LSTM Units: `96`
- Dropout: `0.3`
- Loss: `SparseCategoricalCrossentropy`
- Optimizer: `Adam`
- Evaluation: Accuracy, F1-score, Confusion Matrix

---

## ğŸ“Š Visualizations
- Accuracy vs Validation Accuracy  
- Loss vs Validation Loss  
- Confusion Matrix Heatmap  
- Class Distribution Plot  
- WordClouds per severity level

---

## ğŸ§  API Structure

| Endpoint | Method | Description |
|-----------|---------|-------------|
| `/` | GET | Health check |
| `/predict` | POST | Predicts severity from complaint text |

---

## ğŸ‘¥ Team Workflow

| Role | Responsibility |
|------|----------------|
| **Model Team** | Train and optimize LSTM model |
| **API Team** | Serve model via FastAPI |
| **Dashboard Team** | Consume `/predict` endpoint and visualize results |

---

## âš™ï¸ Tech Stack
- Python 3.10+  
- TensorFlow / Keras  
- TextBlob  
- FastAPI  
- Matplotlib / Seaborn / WordCloud  

---

## ğŸ“ Outputs
- `severity_lstm_tf.keras` â€” model weights  
- `severity_lstm_tf_tokenizer.pkl` â€” tokenizer object  
- `severity_lstm_tf_labels.json` â€” label mappings  
- `/predict` API endpoint for real-time inference

---

## ğŸ§© Future Improvements
- Move from LSTM â†’ Transformer-based model (DistilBERT)  
- Add confidence calibration and explainability layer  
- Containerize API using Docker  
- Integrate continuous retraining pipeline (CI/CD)

---